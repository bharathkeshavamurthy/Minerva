\documentclass[10pt,twocolumn]{IEEEtran}
% \documentclass[12pt, draftcls, onecolumn]{IEEEtran}
\makeatletter
\def\subsubsection{\@startsection{subsubsection}
                                 {3}
                                 {\z@}
                                 {0ex plus 0.1ex minus 0.1ex}
                                 {0ex}
                             {\normalfont\normalsize\bfseries}}
\makeatother
\usepackage[T1]{fontenc}
\usepackage{subfigure}
\usepackage{ulem}
\usepackage{amsmath,enumitem}
\allowdisplaybreaks
\usepackage{hhline}
\usepackage{graphicx}
\usepackage{yfonts,color}
\usepackage{soul,xcolor}
\usepackage{verbatim}
\usepackage{flushend}
\usepackage{amsmath}
\allowdisplaybreaks
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{float}
\usepackage{bm}
\usepackage{url}
\usepackage{array}
\usepackage{cite}
\usepackage{tikz}
\usepackage{framed}
\usepackage{balance}
\usepackage{epsfig,epstopdf}
\usepackage{booktabs}
\usepackage{courier}
\usepackage{subfigure}
\usepackage{pseudocode}
\usepackage{enumerate}
\usepackage{algorithm}
\usepackage{algpseudocode}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\renewcommand{\algorithmicrequire}{\textbf{Initialization:}}  
\renewcommand{\algorithmicensure}{\textbf{Output:}}  
\newcommand{\rom}[1]{\uppercase\expandafter{\romannumeral #1\relax}}
\usepackage{color}
\usepackage{soul,xcolor}
\newcommand{\sst}[1]{\st{#1}}
%\newcommand{\sst}[1]{}
\newcommand{\nm}[1]{{\color{blue}\bf{[NM: #1]}}}
%\newcommand{\nm}[1]{}
\newcommand{\bk}[1]{{\color{magenta}{[BK: #1]}}}
\newcommand{\nmmath}[1]{{\color{blue}\text{\bf{[NM: #1]}}}}
\newcommand{\gs}[1]{{\color{orange}\bf{[GS: #1]}}}
\newcommand{\remove}[1]{{\color{magenta}{\bf REMOVE: [#1]}}}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{cancel}
\newcommand\mst[2][red]{\setbox0=\hbox{$#2$}\rlap{\raisebox{.45\ht0}{\textcolor{#1}{\rule{\wd0}{2pt}}}}#2} 
%\newcommand{\mst}[1]{} 
\newcommand{\add}[1]{{\color{red}{#1}}}
\newcommand{\ull}[1]{\textbf{\color{red}\ul{#1}}}
%\renewcommand{\baselinestretch}{0.9}
\normalem
\title{Learning-based Cognitive Radio Access via
 %A Cognitive Radio MAC Design via
\\
Randomized Point-Based Approximate POMDPs}
\author{Bharath Keshavamurthy~\IEEEmembership{Student Member, ~IEEE} and Nicol\`{o} Michelusi~\IEEEmembership{Senior Member, ~IEEE}
\thanks{Extensions to this work have been submitted to IEEE TCCN \cite{TCCN:paper}.}
\thanks{Part of this research has been funded by NSF under grant CNS-1642982.}
\thanks{B. Keshavamurthy is with ECE, Purdue University, West Lafayette, IN.}
\thanks{N. Michelusi is with the School of ECEE, Arizona State University, AZ.}
\thanks{Email: bkeshava@purdue.edu, nicolo.michelusi@asu.edu}
\vspace{-12mm}}
\begin{document}
\maketitle
\thispagestyle{empty}
\pagestyle{empty} 
\setulcolor{red}
\setul{red}{2pt}
\setstcolor{red}
\begin{abstract}
In this paper, a novel spectrum sensing and access strategy based on approximate Partially Observable Markov Decision Processes (POMDPs) is proposed, wherein a cognitive radio learns the time-frequency correlation model defining the occupancy behavior of incumbents, via the Baum-Welch algorithm, and concurrently devises an optimal strategy to perform spectrum sensing and access that exploits this learned correlation model. To ameliorate the complexity of the POMDP optimization, the PERSEUS algorithm, a randomized point-based value iteration method, is designed, with fragmentation and Hamming distance state filters. Evaluating the cognitive radio throughput against incumbent interference, we demonstrate that, with sensing restrictions, our framework achieves a $6$\% performance gain over that attained by a maximum a-posteriori (MAP) state estimator with prior model knowledge, and outperforms correlation-coefficient based clustering algorithms by an average of $60$\%; additionally, it surpasses a Neyman-Pearson Detector that assumes independence among channels with no sensing restrictions, by an average of $25$\%. Furthermore,
 unlike state-of-the-art algorithms,  the proposed design facilitates the regulation of the trade-off between cognitive radio throughput and incumbent interference
 via a penalty parameter in the underlying MDP.
\end{abstract}
\vspace{-3mm}
\begin{IEEEkeywords}
Cognitive Radio, HMM, POMDP
\end{IEEEkeywords}
\vspace{-5.5mm}
\section{Introduction}\label{I}
With the advent of fifth-generation wireless communication networks, the problem of spectrum scarcity has been exacerbated \cite{7158089}. For some time now, cognitive radio technologies have been in the spotlight as a potential solution to this problem in commercial and military applications. Cognitive radio networks facilitate efficient spectrum utilization by intelligently accessing \emph{white spaces} left unused by the sparse and infrequent transmissions of licensed users while ensuring rigorous incumbent non-interference compliance \cite{4562537}.

A crucial aspect underlying the design of cognitive radio networks is the channel access protocol in the MAC layer of the stack. Additionally, physical design limitations are imposed on the cognitive radio node's spectrum sensor because of quick turnaround times and energy efficiency \cite{5990482}, which restrict the number of channels that can be sensed at any given time. This has led to research in algorithms that first determine which channels to sense and then, via aggregation or correlation exploitation, use the gathered information to perform optimal channel access. In this regard, the current state-of-the-art involves channel sensing and access strategies dictated by multi-armed bandits \cite{7094730}, reinforcement learning agents \cite{6507570}, and other custom heuristics \cite{6956794, 4554696}. Yet, almost all these works, such as \cite{7094730, 6507570}, assume independence across frequencies in the discretized spectrum, which is imprudent because licensed users exhibit correlation across both frequency and time in their channel occupancy behavior: the primary users frequently occupy a set of adjacent channels (frequency correlation), repeating similar motifs in behavior over time (temporal correlation) \cite{6188346, 4213046, McHenry:2006:CSO:1234388.1234389}. This pattern in the occupancy behavior of the incumbents imputes a high correlation among channels, which may be learned and  leveraged for more accurate predictions of spectrum holes. In this paper, we propose a parameter estimation algorithm to learn the aforementioned correlation model, and
an algorithm based on approximate POMDPs to determine the optimal channel sensing and access policy that exploits this learned correlation structure.

\noindent{\bf Related Work:} The works \cite{7094730, 5167826, 7895211} develop spectrum sensing and access algorithms under the assumption that the occupancy behavior of incumbents is independent across both time and frequencies. In our work, we exploit both frequency and temporal correlations. In \cite{7336513}, a compressed spectrum sensing scheme is devised that exploits sparse temporal dynamics in the occupancy of licensed users; in \cite{8571293}, an efficient spectrum sensing strategy is proposed for dense multi-cell cognitive networks, that also exploits the spatial structure of interference; yet, both works neglect frequency correlation.

Spectrum sensing and access strategies in a distributed multi-agent cognitive radio setting have been considered in \cite{6507570} and solved using TD-SARSA with Linear Function Approximation (LFA). However, frequency correlation is precluded, and errors in state estimation are neglected in the decision process. Unlike \cite{6507570}, we consider a model with correlation across frequencies, and we account for uncertainty in the occupancy state via a POMDP formulation. Although the spectrum sensing algorithms detailed in \cite{6956794} consider the correlation in incumbent occupancy behavior across frequencies, the authors assume a perfect, noise-free observation model; instead, we account for the impact of noisy observations in our design. In both \cite{6956794, 4554696}, the authors account for occupancy correlation across both time and frequencies, yet their algorithms use a data-driven strategy wherein pre-loaded databases are employed offline to estimate the correlation models -- which is impractical in non-stationary settings; instead, we present a \emph{fully online framework} that learns the correlation model and simultaneously solves for the optimal channel sensing and access policy. 

Non-adaptive strategies like the Viterbi algorithm in \cite{4554696} employ a fixed channel sensing set throughout their period of operation and  require a-priori knowledge of the transition model of the underlying MDP. In contrast, our solution learns this transition model and concurrently adapts the channel sensing set based on the estimated occupancy transitions and reward/penalty feedback. Next, highlighting our solution against the model-free RL model described in \cite{DQN} which frames the problem under an unknown Markovian time-frequency correlated PU occupancy structure, our solution achieves superior performance owing to more accurate estimation of the MDP transition model parameters and more nuanced approximations based on this correlation in PU occupancy behavior -- namely, fragmentation (frequency correlation) and Hamming distance state filters (temporal correlation). It is also worth noting that none of the works in the state-of-the-art provides a mechanism to \emph{regulate the trade-off} between the throughput attained by the cognitive radio and the interference caused to incumbent transmissions due to inaccurate/overlapping access by the cognitive radio. Our proposed solution facilitates this regulatory mechanism by enabling the tuning of a penalty/cost parameter associated with the underlying MDP model. 

\noindent{\bf Novelty:} In a nutshell, the contributions of this paper are as follows:
we develop an approximate POMDP framework for spectrum sensing and access in a radio environment with multiple licensed users exhibiting Markovian correlations in their occupancy behavior across both time and frequency, assuming a linear, Gaussian observation model with sensing limitations; we develop an online parameter estimation algorithm to learn the incumbents' occupancy correlation model; concurrently, we propose a randomized point-based value iteration algorithm with fragmentation and Hamming distance state filters to find the optimal spectrum sensing and access policy in a computationally tractable way; finally, we benchmark our solution with state-of-the-art algorithms, and demonstrate superior performance. 

\noindent{\bf Extensions:} In an elaboration of our work \cite{TCCN:paper}, the learning-based approximate POMDP framework outlined in this paper has been extended to multi-agent settings, with evaluations in centralized deployments performed on the DARPA SC2 Colosseum, and in distributed deployments performed on a custom ad-hoc test-bed of ESP$32$ WiFi radios.

The rest of the paper is organized as follows: in Sec. \ref{II}, we define the system model, followed by the formulations, approaches, and algorithms in Sec. \ref{III}; in Sec. \ref{IV}, we present numerical evaluations, followed by our conclusions in Sec. \ref{V}.
\vspace{-8mm}
\section{System Model}\label{II}
\noindent {\bf Signal Model:}
We consider a network of $J$ incumbents (Primary Users, PUs) and one cognitive radio (Secondary User, SU) equipped with a spectrum sensor. The goal of the SU is to maximize its throughput by opportunistically accessing portions of the spectrum left unused by the PUs, see Fig. \ref{fig:0}. To this end, the SU should learn how to intelligently access spectrum holes, while ensuring nominal interference with PU transmissions.
We express the discretized wideband frequency domain signal received at the SU
at time index $i$ as
\begin{equation}\label{2}
    Y_k(i) = \sum_{j=1}^{J} H_{j,k}(i)X_{j,k}(i) + V_k(i),
\end{equation}
where  $k {\in} \{1,2,\dots,K\}$
is the frequency domain channel index; $X_{j,k}(i)$ is the signal of the $j$th PU in the frequency domain, and $H_{j,k}(i)$ is the frequency domain channel between the $j$th PU and the SU; $V_k(i) {\sim} \mathcal{CN}(0,\sigma_V^2)$ is circularly symmetric additive complex Gaussian noise, i.i.d across frequency and time, and independent of channel $H$ and PU signal $X$. We further assume that the $J$ PUs employ orthogonal spectrum access (e.g., OFDMA) so that $X_{j,k}(i)X_{g,k}(i){=}0, \forall j{\neq}g$. Thus, letting $j_{k,i}$ be the index of the PU that occupies the $k$th spectrum band at time $i$, $H_{k}(i){\triangleq}H_{j_{k,i},k}(i)$ and $X_{k}(i){\triangleq}X_{j_{k,i},k}(i)$ (with $X_{k}(i){=}0$, if no PU is transmitting in the $k$th spectrum band at time $i$), we can rewrite \eqref{2} as 
\begin{equation}\label{3}
    Y_k(i) = H_{k}(i)X_{k}(i) + V_k(i).
\end{equation}
We model $H_{k}(i)$ as Rayleigh fading with variance $\sigma_H^2$, $H_k {\sim} \mathcal{CN}(0,\sigma_H^2)$, i.i.d. across frequency bands and time.
\begin{figure} [t]
    \centering
    \includegraphics[width=1.0\linewidth]{System_Model_1.png}
    \caption{The radio ecosystem under analysis: an exemplification of the system model discussed in Sec. \ref{II} with $J{=}3$, $K{=}18$, and $\kappa{=}3$.}
    \label{fig:0}
    \vspace{-6mm}
\end{figure}

\noindent {\bf PU Spectrum Occupancy Model:}
We model $X_k(i)$ as $X_k(i){=}\sqrt{P_{tx}}B_k(i)S_k(i)$, where $P_{tx}$ is the transmission power of the PUs, $S_k(i)$ is the transmitted symbol modeled as a constant amplitude signal, $|S_k(i)|{=}1$, i.i.d. over time and across frequency bands;\footnote{If $S_k(i)$ does not have constant amplitude, we can model $H_{k}(i)S_{k}(i){\sim}\mathcal{CN}(0,\sigma_H^2\mathbb{E}[|S_{k}(i)|^2])$, without any modifications to the subsequent analysis.} $B_k(i){\in}\{0,1\}$ is the binary spectrum occupancy variable, with $B_k(i){=}1$, if the $k$th spectrum band is occupied by a PU at time $i$, and $B_k(i){=}0$ otherwise. Therefore, the PU occupancy state in the entire wideband spectrum of interest at time $i$ is modeled as the vector 
\begin{equation}\label{5}
    \vec{B}(i) = [B_1(i), B_2(i), B_3(i), \cdots, B_K(i)]^T {\in} \{0, 1\}^K.
\end{equation}
PUs join and leave the spectrum at random times. To capture this temporal correlation, we model $\vec{B}(i)$ as a Markov process,
\begin{equation}\label{6}
    \begin{aligned}
        \mathbb{P}(\vec{B}(i+1)|\vec{B}(j), \forall j \leq i) = \mathbb{P}(\vec{B}(i+1)|\vec{B}(i)).
    \end{aligned}
\end{equation}
Additionally, when joining the spectrum pool, the PUs may occupy several adjacent spectrum bands and may vary their spectrum needs over time depending on time-varying traffic demands, channel conditions, etc. To capture this behavior, we model $\vec{B}(i)$ as a Markov chain across spectrum bands, i.e., the spectrum occupancy at time $i{+}1$ in frequency band $k$, $B_{k}(i{+}1)$, depends on the occupancy state of the adjacent spectrum band at the same time, $B_{k{-}1}(i{+}1)$, and that of the same spectrum band $k$ in the previous time index $i$, $B_{k}(i)$. This structure is depicted in Fig. \ref{fig:1}, and is described as
\begin{align}\label{7}
&         \mathbb{P}(\vec{B}(i+1)|\vec{B}(i))\\&=
\nonumber
         \mathbb{P}(B_{1}(i+1)|B_{1}(i))
         \prod_{k=2}^{K} \mathbb{P}(B_{k}(i+1)|B_{k}(i), B_{k-1}(i+1)).
\end{align}
Overall, the correlation model is expressed by two coupled Markov chains: one across time and the other across frequencies. We parameterize this two-dimensional Markov chain structure by the vector $\vec{\theta}{=}[\vec{p}\ \vec{q}]^\top$, where $\vec{p}{=}[p_{uv}{=}\mathbb{P}(B_{k}(i{+}1){=}1|B_{k{-}1}(i{+}1){=}u,B_{k}(i){=}v){:} u,v{\in}\{0,1\}]^{\top}$ and $\vec{q}=[q_{w}=\mathbb{P}(B_{1}(i+1)=1|B_{1}(i)=w):w \in \{0,1\}]^\top$. We estimate  $\vec{\theta}$ using the parameter estimation algorithm described in Sec. \ref{III} to obtain the transition model underlying the MDP, given by \eqref{7}. Fig. \ref{fig:1} (b) illustrates three intuitively obvious causes impeding the dexterity of a state estimator to correctly estimate channel occupancies: a decrease in the amount of correlation between successive channels, a lack of sensed data, and size of the discontinuities between successive sensed channels.
\begin{figure} [t]
    \centering
    \includegraphics[width=1.0\linewidth]{System_Model_2.png}
    \caption{The correlation model across time and frequencies underlying the occupancy behavior of PUs in the network (a); and an illustration of the variation of estimation accuracy with channel correlation and sensing strategies, using the Viterbi algorithm as a state estimator in HMM settings for a Markov chain across channels ($\mathbb{P}(\vec{B}_{k{+}1}(i){|}\vec{B}_{k}(i))$), with $\mathbb{P}(\vec{B}_{k}(i){=}1){=}0.6$}
    \label{fig:1}
    \vspace{-6mm}
\end{figure}

\noindent{\bf Spectrum Sensing Model:}
To detect the available spectrum holes, the SU performs spectrum sensing. However, owing to physical design limitations of its spectrum sensor \cite{5990482}, it can sense at most $\kappa$ out of $K$ spectrum bands at any given time, with $1{\leq}\kappa{\leq}K$. Let $\mathcal K_{i}{\subseteq}\{1,2,\dots,K\}$ with $|\mathcal K_i|{\leq}\kappa$ be the set of indices of spectrum bands sensed by the SU at time $i$, part of our design.
Then, we define the observation vector
\begin{equation}\label{8}
    \vec{Y}(i) = [Y_k(i)]_{k {\in} \mathcal K_i},
\end{equation}
with $Y_k(i)$ given by \eqref{3}.
The true states $\vec{B}(i)$ encapsulate the actual occupancy state of the PUs, and the measurements $\vec{Y}(i)$ at the SU are noisy observations of these true states, which are modeled to be the observed states of an HMM. Given $\vec{B}(i)$ and $\mathcal K_i$, the probability density function of $\vec{Y}(i)$ is
\begin{equation}\label{9}
    f(\vec{Y}(i)|\vec{B}(i), \mathcal K_i) = \prod_{k \in \mathcal K_i} f(Y_k(i)|B_k(i)),
\end{equation}
owing to the independence of channels (given the occupancy states), noise, and transmitted symbols across frequency bands. Moreover, from \eqref{3},
\begin{equation}\label{10}
 Y_k(i)|B_k(i) \sim \mathcal{CN}(0, \sigma_H^2P_{tx}B_k(i) + \sigma_V^2).
\end{equation}

\noindent{\bf POMDP Agent Model:}
We model the SU as a POMDP agent, whose goal is to devise an optimal sensing and access policy to maximize its throughput while ensuring minimal interference with PU transmissions. The agent's limited sensing capabilities coupled with its noisy observations result in uncertainty on the PU spectrum occupancy state. The transition model of the underlying MDP, given by \eqref{7}, is denoted by $\mathbf{A}$ and is learned by the agent by interacting with the radio environment (see Sec. \ref{III}). The observation model in \eqref{9} is denoted by $\mathbf{M}$, with $f(Y_k(i)|B_k(i))$ given by \eqref{10}. 

We model the POMDP as a tuple $(\mathcal B,\mathcal{A},\mathcal{Y},\mathbf{A},\mathbf{M})$ where $\mathcal{B}{\equiv}\{0,1\}^K$ represents the state space of the underlying MDP, given by all possible realizations of the spectrum occupancy vector $\vec{B}$, as described by \eqref{5}; $\mathcal{A}$ represents the action space of the agent, given by all possible combinations in which $\kappa$ spectrum bands are chosen to be sensed out of $K$ at any given time; and $\mathcal{Y}$ represents the observation space of the agent based on the aforementioned signal model. The state of the POMDP at time $i$ is given by the \emph{prior belief} $\beta_i$, which represents the probability distribution of the underlying MDP state $\vec{B}(i)$, given the information collected by the agent up to time $i$, but before collecting the new information in time-slot $i$. At the beginning of each time index $i$, given $\beta_i$, the agent selects $\kappa$ spectrum bands out of $K$, according to a policy $\mathcal K_i{=}\pi(\beta_i)$, which defines the sensing set $\mathcal K_i$, performs spectrum sensing  on these spectrum bands, observes $\vec{Y}(i){\in} \mathcal{Y}$, and updates its \emph{posterior belief} $\hat{\beta}_i$ of the current spectrum occupancy $\vec{B}(i)$ as 
\begin{align}\label{11}
\nonumber
\hat\beta_i(\vec{B}') &= \mathbb{P}(\vec{B}(i) = \vec{B}'|\vec{Y}(i), \mathcal K_i, \beta_i)\\&=
\frac{\mathbb{P}(\vec{Y}(i)|\vec{B}', \mathcal{K}_i) \beta_i(\vec{B}')}{
\sum_{\vec{B}'' {\in} \{0,1\}^K} \mathbb{P}(\vec{Y}(i)|\vec{B}'', \mathcal{K}_i) \beta_i(\vec{B}'')}.
\end{align}
Given the posterior belief $\hat{\beta}_i$, we estimate the spectrum occupancy $\vec{B}(i)$
based on the MAP criterion
$$
\vec{\phi}(\hat{\beta}_{i})\triangleq \argmax_{\vec{B} {\in} \mathcal{B}} \hat{\beta}_{i}(\vec{B}),
$$
with the $k$th spectrum channel estimate given by $\phi_k(\hat{\beta}_{i})$. If  the $k$th channel is deemed idle, i.e., $\phi_{k}(\hat{\beta}_{i}){=}0$, the SU accesses the channel to deliver its network flows. Else, it leaves it untouched. Given the PU occupancy state $\vec{B}(i)$ and posterior belief $\hat\beta_i$, the reward metric of the POMDP is given by the number of \emph{truly idle} bands detected by the SU, accounting for the throughput maximization aspect of the agent's objective, and a penalty for \emph{missed detections} accounting for interference to the PUs, i.e.,
\begin{equation}
\nonumber
    R(\vec{B}(i), \hat{\beta}_i){=}\sum_{k=1}^{K} (1{-}B_k(i))(1{-}\phi_k(\hat{\beta}_{i})){-}\lambda B_k(i)(1 - \phi_k(\hat{\beta}_i)),
\end{equation}
where $\lambda{>}0$ is a penalty cost. After performing data transmission, the SU computes the prior belief for the next time-slot based on the learned Markov chain dynamics
(see Sec. \ref{III}) as
\begin{equation}\label{13}
    \beta_{i+1}(\vec{B}'')=\sum_{\vec{B}'}\mathbb{P}(\vec{B}(i+1) = \vec{B}''|\vec{B}(i)=\vec{B}')\hat{\beta}_{i}(\vec{B}').
\end{equation}
We denote the functions that map the prior belief $\beta_i$ to the posterior belief $\hat\beta_i$ through the spectrum sensing action $\mathcal K_i$ and the observation signal $\vec{Y}(i)$, and the posterior belief $\hat\beta_i$ to the next prior belief $\beta_{i+1}$ as
$$\hat\beta_i{=}\hat{\mathbb B}(\beta_i, \mathcal K_i, \vec{Y}(i)),\ \beta_{i+1}{=}{\mathbb B}(\hat\beta_i),\text{ respectively}.$$
The goal is to determine an optimal spectrum sensing policy to maximize the infinite-horizon discounted reward, with discount factor $0{<}\gamma{<}1$,
\begin{equation}\label{14}
    \pi^{*}{=}\argmax_{\pi} V^{\pi}(\beta) \triangleq \mathbb{E}_{\pi} \Big[\sum_{i=1}^{\infty} \gamma^{i} R(\vec{B}(i), \hat{\beta}_i)|\beta_0 {=}\beta\Big],
\end{equation}
where $\beta_0$ is the initial belief, $\hat\beta_i$ is the posterior belief induced by policy $\mathcal K_i{=}\pi(\beta_i)$ and the observation $\vec{Y}(i)$ via $\hat\beta_i{=}\hat{\mathbb B}(\beta_i, \mathcal K_i, \vec{Y}(i))$, and we have defined the value function $V^{\pi}(\beta)$ under policy $\pi$ starting from belief $\beta$.
The optimal policy $\pi^*$ and the corresponding optimal reward $V^*(\beta)$ are the solutions of Bellman's optimality equation $V^*{=}\mathcal{H}[V^*]$, where the operator $V_{t+1}{=}\mathcal {H}[V_{t}]$ is defined as
\begin{align}\label{16}
\nonumber
        V_{t+1}(\beta) = &\max_{\mathcal{K} {\in} \mathcal{A}} \sum_{\vec{B} {\in} \mathcal{B}} \beta(\vec{B}) \mathbb{E}_{\vec{Y}|\vec{B}, \mathcal{K}} \Big[R(\vec{B}, \hat{\mathbb{B}}(\beta, \mathcal{K}, \vec{Y}))\\ &+\gamma V_{t}(\mathbb{B}(\hat{\mathbb{B}}(\beta, \mathcal{K}, \vec{Y})))\Big],\ \forall \beta.
\end{align}
This problem can be solved using the value iteration algorithm, i.e., by solving \eqref{16} iteratively until convergence to a fixed point. However, two challenges arise in our formulation:
\begin{itemize}[leftmargin=*]
\item The parameter vector $\vec{\theta}$ is unknown, hence the belief updates 
$\hat{\mathbb B}$ and $\mathbb B$ cannot be computed;
\item The number of states of the underlying MDP scales exponentially with the number of spectrum bands, resulting in high-dimensional belief space, hence, solving equation \eqref{16} exactly is computationally intractable.
\end{itemize}
To overcome these challenges, in the next section, we present a framework to estimate the transition model of the underlying MDP online, while concurrently utilizing this learned model to solve for the optimal policy via PERSEUS: an approximate, randomized point-based value iteration algorithm \cite{DBLP:journals/corr/abs-1109-2145}.
    \vspace{-3mm}
\section{Approaches and Algorithms}\label{III}
\noindent{\bf Occupancy Behavior Model Estimation:}
In real-world implementations of cognitive radios, the correlation model defining the occupancy behavior of the PUs is unknown to the SUs, and therefore needs to be learned over time. The learned model is then fed back to the POMDP agent to compute the  optimal spectrum sensing and access policy. Inherently, the approach constitutes solving the Maximum Likelihood Estimation (MLE) problem
\begin{equation}\label{17}
\vec{\theta}^{*} = \argmax_{\vec{\theta}} \log\Big(\sum_{\mathbf{B}} \mathbb{P}(\mathbf{B}, \mathbf{Y}| \vec{\theta})\Big),
\end{equation}
where $\vec{\theta}{=}[\vec{p}\ \vec{q}]^{T}$, $\mathbf{Y}{=}[\vec{Y}(i)]_{i{=}1}^{\tau}$, $\mathbf{B}{=}[\vec{B}(i)]_{i{=}1}^{\tau}$,
and $\tau$ refers to the learning period of the parameter estimator: this may be equal to the entire duration of the POMDP agent's interaction with the radio environment, implying simultaneous model learning, or can be a predefined parameter learning period before triggering the POMDP agent. This problem can be solved using the 
Baum-Welch algorithm, a special instance of the Expectation-Maximization (EM) algorithm used to find the unknown parameters of a HMM. Specifically, the E-step is given by
\begin{equation}
    Q(\vec{\theta}|\vec{\theta}^{(t)}) = \mathbb{E}_{\mathbf{B}|\mathbf{Y}, \vec{\theta}^{(t)}} \Big[ \log \Big(\mathbb{P}(\mathbf{B}, \mathbf{Y}|\vec{\theta}^{(t)})\Big)\Big].
\end{equation}
The term $Q(\vec{\theta}|\vec{\theta}^{(t)})$ can be computed by employing the Forward-Backward algorithm \cite{Rabiner_1989} using the current estimate $\vec{\theta}^{(t)}$. The M-step constitutes
\begin{equation}
\vec{\theta}^{(t+1)}
 = \argmax_{\vec{\theta}} Q(\vec{\theta}|\vec{\theta}^{(t)}),
\end{equation}
which involves re-estimation of the maximum likelihood parameter vector $\vec{\theta}$ \cite{Rabiner_1989} using the statistics obtained from the Forward-Backward algorithm.

\noindent{\bf The PERSEUS Algorithm:}
We solve for the optimal spectrum sensing and access policy, formulated as a POMDP, in parallel with the parameter estimation algorithm, employing the model estimates until both the EM and the POMDP algorithms converge. As discussed in Sec. \ref{II} of this article, solving the Bellman equation \eqref{16} for POMDPs with large state and action spaces using exact value iteration is computationally infeasible \cite{DBLP:journals/corr/abs-1109-2145}. Hence, we resort to approximate value iteration methods to ensure that the system scales well to a large number of bands in the spectrum of interest. One such method, the PERSEUS algorithm \cite{DBLP:journals/corr/abs-1109-2145}, is a randomized point-based approximate value iteration technique that involves an initial phase of determining a set of so-called \emph{reachable beliefs} $\tilde{\mathcal{B}}$ by allowing the agent to randomly interact with the radio environment. The goal of PERSEUS is to improve the value of all the belief points in this set $\tilde{\mathcal{B}}$ by updating the value of only a subset of these belief points, chosen iteratively at random. Using the notion that, for finite-horizon POMDPs, $V^*$ in \eqref{16} can be approximated by a piece-wise linear and convex function \cite{DBLP:journals/corr/abs-1109-2145}, PERSEUS operates on the core idea that the value function at iteration $t$ can be parameterized by a set of hyperplanes $\{\vec{\alpha}_{t}^{u}\}$, $u {\in} \{1,2,\dots,|\tilde{\mathcal{B}}|\}$, each representing a region of the belief space for which it is the maximizing element, and each associated with an optimal spectrum sensing action $\mathcal K_t^{u}$. That is, when operating with belief $\beta$, the value function is approximated as
\begin{equation}
    \begin{aligned}\label{40}
        V_{t}(\beta) \approx \beta \cdot \vec{\alpha}_{t}^{u^*},
        \ 
        u^* = \argmax_{u\in\{1,2,\dots,|\tilde{\mathcal{B}}|\}} \beta \cdot \vec{\alpha}_{t}^{u},
    \end{aligned}
\end{equation}
and the optimal spectrum sensing action is $\mathcal K_t^{u^*}$, where $\beta\cdot\vec{\alpha}{=}\sum_{\vec{B}}\beta(\vec{B})\vec{\alpha}(\vec{B})$ denotes inner product. The set of hyperplanes $\{\vec{\alpha}_{t}^{u}\}$ associated with the set $\tilde{\mathcal{B}}$ are improved over multiple iterations of PERSEUS: given $\{\vec{\alpha}_{t}^{u}\}$ and the optimal spectrum sensing actions $\{\mathcal K_{t}^{u}\}$ at iteration $t$, a PERSEUS iteration generates a new set of hyperplanes $\{\vec{\alpha}_{t+1}^{u}\}$ and associated spectrum sensing actions
$\{\mathcal K_{t+1}^{u}\}$, as we now describe. Let $\tilde{\mathcal{U}}$ be the set of unimproved belief points (initially, $\tilde{\mathcal{U}}{=}\tilde{\mathcal{B}}$). Then, a belief $\beta_u$ is picked randomly from $\tilde{\mathcal{U}}$. Next, a \emph{backup} operation is performed on $\beta_u$ to determine a new associated hyperplane and spectrum sensing action as in \cite{DBLP:journals/corr/abs-1109-2145},
\begin{equation}\label{20}
    \vec{\alpha}_{t+1}^{u}=\Xi_{\mathcal K_{t+1}^{u}}^{u},\ 
    \mathcal K_{t+1}^{u}=\argmax_{\mathcal{K} \in \mathcal{A}} \beta_u \cdot \Xi_{\mathcal{K}}^{u},
\end{equation}
where $\Xi_{\mathcal{K}}^{u}$ is the hyperplane corresponding to a one-step look-ahead under action $\mathcal K$ and belief $\beta_u$, with components
\begin{align*}
\Xi_{\mathcal{K}}^{u}(\vec{B}) = &\mathbb{E}_{\vec{Y}|\vec{B}, \mathcal{K}} \Big[R(\vec{B}, \hat{\mathbb{B}}(\beta_{u}, \mathcal{K}, \vec{Y}))\\
&+\gamma 
        \sum_{\vec{B}'}\mathbb{P}(\vec{B}(i+1){=} \vec{B}'|\vec{B}(i){=}\vec{B})
                \Xi_{\mathcal{K}, \vec{Y}}^{u}(\vec{B}')\Big]
\nonumber
\end{align*}
and $\Xi_{\mathcal{K}, \vec{Y}}^{u}$ is the hyperplane associated with the future value function computed from the previous set of hyperplanes as
\begin{equation}
    \Xi_{\mathcal{K}, \vec{Y}}^{u}=\argmax_{\alpha_{t}^{u'}, u' {\in} \{1, 2, \dots, |\tilde{\mathcal{B}}|\}} \mathbb{B}(\hat{\mathbb{B}}(\beta_{u}, \mathcal{K}, \vec{Y}))\cdot\alpha_{t}^{u'},
\nonumber
\end{equation}
under the new belief $\mathbb{B}(\hat{\mathbb{B}}(\beta_{u}, \mathcal{K}, \vec{Y}))$ reached from $\beta_{u}$, under action $\mathcal{K}$ and observation $\vec{Y}$, in one step. At this point, $\beta_{u}{\cdot}\vec{\alpha}_{t+1}^{u}$ is the approximate value function associated with the belief $\beta_u$. If $\beta_{u}{\cdot}\vec{\alpha}_{t+1}^{u}{\geq}V_{t}(\beta_{u})$, the newly defined hyperplane generates an improved value function; otherwise ($\beta_{u}{\cdot}\vec{\alpha}_{t+1}^{u}{<}V_{t}(\beta_{u})$), the value function is worsened and the previous hyperplane is kept, hence $\vec{\alpha}_{t+1}^{u}{:=}\vec{\alpha}_{t}^{u}$ and $\mathcal K_{t+1}^{u}{:=}\mathcal K_{t}^{u}$. Finally, the belief $\beta_u$ is removed from $\tilde{\mathcal{U}}$, along with all belief points that are improved by the newly added hyperplane:
$$
\tilde{\mathcal{U}}\leftarrow \tilde{\mathcal{U}}\setminus\{\beta_u\}\setminus
\{\beta'\in\tilde{\mathcal{U}}:\beta'{\cdot}\vec{\alpha}_{t+1}^{u}\geq V_t(\beta')\}.
$$
This operation continues until the set $\tilde{\mathcal{U}}$ is empty, which constitutes a single PERSEUS iteration. The PERSEUS iterations continue until a termination condition is met, i.e., $|V_{t{+}1}(\beta){-}V_{t}(\beta)|{<}\epsilon,\ \forall \beta{\in} \tilde{\mathcal{B}},\ \epsilon{>}0$. The belief update procedure outlined in \eqref{11} is an essential aspect of POMDPs, which can turn into a performance bottleneck for large state spaces due to the inherent iteration over all possible states. In order to circumvent this problem, we employ a \emph{fragmentation heuristic}, i.e., we fragment the spectrum into smaller, independent sets of correlated channels and then run the PERSEUS algorithm on these fragments by leveraging multi-processing and multi-threading tools available at our disposal in software frameworks. Furthermore, we avoid iterating over all possible states by employing a \emph{belief update simplification heuristic}, i.e., we allow only those state transitions we deem to be the most probable -- for example, only those that involve a Hamming distance of up to $3$ between the previous and current state vectors in a radio environment with $18$ frequency channels.
\begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{Evaluation_1.png}
    \caption{Convergence of: MSE of the EM algorithm to estimate $\vec{\theta}$; and Loss of the fragmented PERSEUS algorithm with belief update simplification}
    \label{fig:4}
    \vspace{-6mm}
\end{figure}
\vspace{-3mm}
\section{Numerical Evaluations}\label{IV}
\noindent{\bf Simulation Setup:}
We simulate a radio environment with $J{=}3$ PUs occupying a set of $K{=}18$ channels, each of bandwidth $\text{BW}{=}160 \text{kHz}$, according to a Markovian time-frequency correlation structure with parameters $\vec{p}{=}[p_{00}{=}0.1,p_{01}{=}p_{10}{=}0.3,p_{11}{=}0.7]^\top$ and $\vec{q}{=}[q_{0}{=}0.3,q_{1}{=}0.8]^\top$. An SU intelligently tries to access the available white spaces in order to maximize its own throughput, while limiting interference to licensed users. We model the expected SINRs at the SU and PU receivers, averaged out with respect to fading and conditional on the SU and PU access decisions, as follows: at the PU receivers,
$\text{SINR}_{\text{PU}}{=}17\text{dB}$ when there is no interference from the SU, and $\text{SINR}_{\text{PU}}{=}6\text{dB}$ under SU interference; 
at the SU receiver, $\text{SINR}_{\text{SU}}{=}11\text{dB}$ when the channel is not occupied by a PU, and $\text{SINR}_{\text{SU}}{=}{-}6\text{dB}$ under PU interference. We denote the actual SINR realizations in frequency $k$ and time index $i$ by $\text{SINR}_{\text{SU}}(k,i)$ and $\text{SINR}_{\text{PU}}(k,i)$, with $\text{SINR}_{\text{SU}}(k,i){=}0$ if the SU remains idle. The SU can sense at most $\kappa{=}6$ out of $K{=}18$ channels at any given time, it is backlogged and accesses all the channels deemed idle. Hence, the average SU throughput over $T$ time-slots is given by $$C^{\text{SU}} = \frac{1}{T}\sum_{i=1}^T \sum_{k=1}^{K} R_{\text{SU}} \cdot \mathcal{I}\left(\text{SINR}_{\text{SU}}(k,i) \geq 2^{R_{\text{SU}}/\text{BW}} - 1\right),$$ where $R_{\text{SU}}{=}0.6$Mbps is the transmission rate of the SU on each frequency channel. Similarly, the throughput attained by the PUs over the same time interval, normalized over time and the number of transmission attempts, is given by $$C^{\text{PUs}}{=}\frac{\sum_{i=1}^{T}\sum_{k=1}^{K}R_{\text{PU}}B_{k}(i)\mathcal{I}\left(\text{SINR}_{\text{PU}}(k,i){\geq}2^{R_{\text{PU}}/\text{BW}}{-}1\right)}{\sum_{i=1}^T\sum_{k=1}^{K}B_{k}(i)},$$ where $R_{\text{PU}}{=}0.9$Mbps is the transmission rate of the PUs on each frequency channel. To solve for the optimal PERSEUS policy, we employ a discount factor of $\gamma{=}0.9$ and a termination threshold of $\epsilon{=}10^{-5}$.
\begin{figure}[t]
    \centering
    \includegraphics[width=0.96\linewidth]{Evaluation_2_Reduced.png}
    \caption{Evaluation of $C^{\text{SU}}$ versus $C^{\text{PUs}}$ for different values of the penalty $\lambda$ and noise power $\sigma_{V}^{2}$; comparisons with state-of-the-art and our solution with model foresight}
    \label{fig:8}
    \vspace{-6mm}
\end{figure}

\noindent{\bf Evaluations:}
The plot depicted in Fig. \ref{fig:4} shows the Mean Squared Error (MSE) convergence of the parameter estimation algorithm to determine the time-frequency correlation parameters $\vec{\theta}$, averaged over $45{\cdot} 10^3$ iterations. Assuming a time-slot duration of $3$ms, this corresponds to an observation and estimation period of $135$s. Starting with initial estimates of $0.5$ for the parameters $p_{uv}$ and $q_{w}$, ${\forall}u,v,w{\in}\{0,1\}$, the EM algorithm iteratively reduces the MSE, as it goes through the E and M steps, and converges to the true transition model with an error of $10^{-8}$. Fig. \ref{fig:4} also illustrates the convergence of the PERSEUS algorithm, on the same time scale and in the same simulation run. The loss metric is defined as the difference in utility obtained by our PERSEUS algorithm, denoted by $R_{P}(\vec{B}(i), \hat{\beta}_{i})$ at time-slot $i$, and an \emph{Oracle} which knows the exact occupancy behavior of PUs in the network, with utility $R_{O}(\vec{B}(i))$.

In Fig. \ref{fig:8}, we evaluate the performance of our solution in terms of SU and PU network throughputs over varying values of the penalty term $\lambda$: we find that our POMDP agent decides to limit channel access when the penalty is high, leading to lower SU network throughput and PU interference; conversely, it follows a more lenient channel access strategy when the penalty is low, resulting in higher SU network throughput and PU interference. Compared to a variant of PERSEUS in which the agent has perfect knowledge of the correlation model, we observe small performance degradation due to the concurrent model learning. We appraise the performance of our framework -- in terms of the \emph{achieved SU throughput vis-Ã -vis PU throughput degradation} -- against state-of-the-art algorithms including RL-based solutions, all with sensing restrictions of 6 unless otherwise stated:
\begin{itemize}[leftmargin=*]
\item Two variants of Minimum Entropy Merging (MEM) with Channel Correlation Estimation (CCE) and Markov Process Estimation (MPE) -- one with Greedy Clustering (GC) and the other with Minimum Entropy Increment (MEI) Clustering \cite{6956794}, both with correlation threshold $0.77$: we show an average improvement of $60$\%;
\item  The Viterbi algorithm \cite{4554696} with a-priori model information: we demonstrate a $6$\% upswing;
\item Neyman-Pearson Detector \cite{5167826}, which neglects time-frequency correlation among channels and senses all channels (\emph{no sensing restrictions}); AND fusion rule across 300 different samplings, and a detection threshold determined to achieve a false alarm probability of $30$\%: we demonstrate $25$\% enhancement;
\item TD-SARSA with LFA \cite{6507570} in single-agent deployment settings, with belief update heuristic constant $0.9$, discount factor $0.9$, exploration factor $0.01$, and raw false alarm probability $5$\%: we perform $3$\% better; and
\item Adaptive Deep Q-Network (DQN) \cite{DQN} with experiential replay (memory size $10^{6}$), $2048$ input neurons, $2{\times}4096$ neurons with ReLU activation functions, MSE cost function with an Adam optimizer, exploration factor $0.1$, learning rate $10^{-4}$, and batch size $32$: we perform $9$\% better.
\end{itemize}
Besides, our design facilitates the regulation of the trade-off between cognitive radio throughput and incumbent interference via the penalty term $\lambda$.
\vspace{-9mm}

\section{Conclusion}\label{V}
In this paper, we formulate the optimal spectrum sensing and access problem as an approximate POMDP, which leverages learning of the spectrum occupancy correlation model of the PU via the Baum-Welch algorithm. Through system simulations, we demonstrate the advantages of exploiting the correlation structure -- as opposed to Neyman-Pearson Detector which assumes independence -- and of adapting the spectrum sensing decision to optimize the performance -- as opposed to Viterbi, which uses a fixed sensing strategy. We demonstrate the feasibility of a concurrent learning and decision-making framework, as opposed to correlation-coefficient based clustering algorithms which rely on pre-loaded datasets for determining the PU occupancy correlation model. Our framework enables a critical feature: the ability of the SU to regulate the interference caused to PUs, by adjusting a penalty parameter.
\vspace{-9mm}
\bibliographystyle{IEEEtran}
\bibliography{ref}
\end{document}